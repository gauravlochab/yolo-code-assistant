{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Embedding Evaluation\n",
    "\n",
    "This notebook evaluates the quality of code embeddings generated by the Jina model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from src.yolo_assistant.indexer import CodeEmbedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedder\n",
    "embedder = CodeEmbedder()\n",
    "\n",
    "# Test cases: similar and dissimilar code snippets\n",
    "test_cases = [\n",
    "    # Similar functions (training related)\n",
    "    (\"def train_model(model, data, epochs=100):\",\n",
    "     \"def train_yolo(yolo_model, dataset, num_epochs=100):\"),\n",
    "    \n",
    "    # Similar functions (inference related)\n",
    "    (\"def predict(model, image):\",\n",
    "     \"def inference(net, img):\"),\n",
    "    \n",
    "    # Different functions\n",
    "    (\"def train_model(model, data):\",\n",
    "     \"def save_checkpoint(state, filename):\"),\n",
    "    \n",
    "    # Same concept, different implementation\n",
    "    (\"class YOLO(nn.Module):\",\n",
    "     \"class YOLOv8(BaseModel):\"),\n",
    "]\n",
    "\n",
    "# Calculate similarities\n",
    "for i, (code1, code2) in enumerate(test_cases):\n",
    "    emb1 = embedder.embed_text(code1)\n",
    "    emb2 = embedder.embed_text(code2)\n",
    "    \n",
    "    similarity = cosine_similarity([emb1], [emb2])[0][0]\n",
    "    \n",
    "    print(f\"Test case {i+1}:\")\n",
    "    print(f\"  Code 1: {code1[:50]}...\")\n",
    "    print(f\"  Code 2: {code2[:50]}...\")\n",
    "    print(f\"  Cosine similarity: {similarity:.4f}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for various code patterns\n",
    "code_patterns = [\n",
    "    # Functions\n",
    "    \"def forward(self, x): return self.model(x)\",\n",
    "    \"def backward(self, grad): return grad * self.weight\",\n",
    "    \"def loss(self, pred, target): return F.cross_entropy(pred, target)\",\n",
    "    \n",
    "    # Classes\n",
    "    \"class Model(nn.Module): pass\",\n",
    "    \"class Dataset(torch.utils.data.Dataset): pass\",\n",
    "    \"class Trainer: pass\",\n",
    "    \n",
    "    # Imports\n",
    "    \"import torch\",\n",
    "    \"from ultralytics import YOLO\",\n",
    "    \"import numpy as np\",\n",
    "]\n",
    "\n",
    "embeddings = embedder.embed_batch(code_patterns)\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Analyze embedding statistics\n",
    "print(\"Embedding Statistics:\")\n",
    "print(f\"  Shape: {embeddings_array.shape}\")\n",
    "print(f\"  Mean: {embeddings_array.mean():.4f}\")\n",
    "print(f\"  Std: {embeddings_array.std():.4f}\")\n",
    "print(f\"  Min: {embeddings_array.min():.4f}\")\n",
    "print(f\"  Max: {embeddings_array.max():.4f}\")\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(embeddings_array.flatten(), bins=50, alpha=0.7)\n",
    "plt.title('Embedding Value Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([emb for emb in embeddings_array.T], showfliers=False)\n",
    "plt.title('Embedding Dimension Statistics')\n",
    "plt.xlabel('Dimension Index')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(range(0, len(embeddings_array[0]), 100), range(0, len(embeddings_array[0]), 100))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query-Code Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query to code matching\n",
    "queries = [\n",
    "    \"How to train a YOLO model?\",\n",
    "    \"Export model to ONNX format\",\n",
    "    \"Data augmentation techniques\",\n",
    "    \"Calculate mAP metric\",\n",
    "]\n",
    "\n",
    "code_snippets = [\n",
    "    \"def train(model, dataloader, epochs=100): optimizer = Adam(model.parameters())\",\n",
    "    \"def export_onnx(model, filepath): torch.onnx.export(model, dummy_input, filepath)\",\n",
    "    \"def augment_image(image): return transforms.RandomHorizontalFlip()(image)\",\n",
    "    \"def calculate_map(predictions, ground_truth): return mean_average_precision(predictions, ground_truth)\",\n",
    "    \"def load_dataset(path): return Dataset(path)\",\n",
    "    \"def save_checkpoint(model, path): torch.save(model.state_dict(), path)\",\n",
    "]\n",
    "\n",
    "# Embed queries and code\n",
    "query_embeddings = embedder.embed_batch(queries)\n",
    "code_embeddings = embedder.embed_batch(code_snippets)\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = cosine_similarity(query_embeddings, code_embeddings)\n",
    "\n",
    "# Display results\n",
    "print(\"Query-Code Similarity Matrix:\")\n",
    "print(\"(Rows: Queries, Columns: Code snippets)\\n\")\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"Query: {query}\")\n",
    "    similarities = similarity_matrix[i]\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    \n",
    "    print(f\"  Best match: {code_snippets[best_match_idx][:60]}...\")\n",
    "    print(f\"  Similarity: {similarities[best_match_idx]:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create diverse code samples\n",
    "code_samples = [\n",
    "    # Training functions\n",
    "    \"def train(model, data): pass\",\n",
    "    \"def training_loop(net, dataset): pass\",\n",
    "    \"def fit(model, X, y): pass\",\n",
    "    \n",
    "    # Loss functions\n",
    "    \"def focal_loss(pred, target): pass\",\n",
    "    \"def iou_loss(boxes1, boxes2): pass\",\n",
    "    \"def classification_loss(logits, labels): pass\",\n",
    "    \n",
    "    # Data processing\n",
    "    \"def preprocess_image(img): pass\",\n",
    "    \"def augment_data(batch): pass\",\n",
    "    \"def normalize(tensor): pass\",\n",
    "    \n",
    "    # Model architecture\n",
    "    \"class ConvBlock(nn.Module): pass\",\n",
    "    \"class Backbone(nn.Module): pass\",\n",
    "    \"class DetectionHead(nn.Module): pass\",\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "sample_embeddings = embedder.embed_batch(code_samples)\n",
    "\n",
    "# Reduce dimensionality for visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(sample_embeddings)\n",
    "\n",
    "# Cluster embeddings\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "clusters = kmeans.fit_predict(sample_embeddings)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "categories = ['Training', 'Loss', 'Data', 'Architecture']\n",
    "\n",
    "for i, (x, y) in enumerate(embeddings_2d):\n",
    "    plt.scatter(x, y, c=colors[i//3], s=100)\n",
    "    plt.annotate(code_samples[i][:20] + '...', (x, y), fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.title('Code Embedding Clusters (PCA Projection)')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "\n",
    "# Add legend\n",
    "for i, cat in enumerate(categories):\n",
    "    plt.scatter([], [], c=colors[i], label=cat, s=100)\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
